#!/bin/bash

# Unit Test Runner with Statistics
# This script runs all unit tests in the project and provides detailed statistics

# Colors for output formatting
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color
BOLD='\033[1m'

# Print header
echo -e "${BOLD}${BLUE}=========================================${NC}"
echo -e "${BOLD}${BLUE}       ClickUp JSON Manager Tests        ${NC}"
echo -e "${BOLD}${BLUE}=========================================${NC}"
echo ""

# Define variables for statistics
total_tests=0
passed_tests=0
failed_tests=0
skipped_tests=0
error_tests=0
total_time=0

# Create temporary directory for test results
tmp_dir=$(mktemp -d)
results_file="$tmp_dir/test_results.txt"
coverage_file="$tmp_dir/coverage.xml"
failed_tests_file="$tmp_dir/failed_tests.txt"

# Check if coverage is installed
if command -v coverage &> /dev/null; then
    has_coverage=true
else
    has_coverage=false
    echo -e "${YELLOW}Coverage module not found. Test coverage statistics will not be available.${NC}"
    echo -e "${YELLOW}Install with: pip install coverage${NC}"
    echo ""
fi

# Function to run tests in a module
run_module_tests() {
    local module=$1
    local module_name=$(basename "$module")
    
    echo -e "${CYAN}Running tests in ${module_name}...${NC}"
    
    # Measure execution time
    start_time=$(date +%s.%N)
    
    if [ "$has_coverage" = true ]; then
        # Run tests with coverage
        coverage run --source=refactor -m unittest discover -s "$module" -p "test_*.py" > "$results_file" 2>&1
    else
        # Run tests without coverage
        python -m unittest discover -s "$module" -p "test_*.py" > "$results_file" 2>&1
    fi
    
    exit_code=$?
    end_time=$(date +%s.%N)
    
    # Calculate execution time
    module_time=$(echo "$end_time - $start_time" | bc)
    total_time=$(echo "$total_time + $module_time" | bc)
    
    # Get test result statistics - ensure they are integers
    local module_total
    module_total=$(grep -c "test_" "$results_file" || echo 0)
    
    local module_errors
    module_errors=$(grep -c "ERROR:" "$results_file" || echo 0)
    
    local module_failures
    module_failures=$(grep -c "FAIL:" "$results_file" || echo 0)
    
    local module_skipped
    module_skipped=$(grep -c "skipped=" "$results_file" || echo 0)
    
    # If no tests were found, try another approach
    if [ "$module_total" -eq 0 ]; then
        module_total=$(python -m unittest discover -s "$module" -p "test_*.py" -v 2>&1 | grep -c "test_" || echo 0)
    fi
    
    # Calculate module_passed carefully
    local module_passed
    if [ "$module_total" -eq 0 ]; then
        module_passed=0
    else
        module_passed=$((module_total - module_errors - module_failures - module_skipped))
        if [ "$module_passed" -lt 0 ]; then
            module_passed=0
        fi
    fi
    
    # Update global statistics
    total_tests=$((total_tests + module_total))
    passed_tests=$((passed_tests + module_passed))
    failed_tests=$((failed_tests + module_failures))
    error_tests=$((error_tests + module_errors))
    skipped_tests=$((skipped_tests + module_skipped))
    
    # Display module results
    if [ $exit_code -eq 0 ]; then
        echo -e "${GREEN}✓ All tests passed in ${module_name} ($module_total tests, $(printf "%.2f" $module_time)s)${NC}"
    else
        echo -e "${RED}✗ Tests failed in ${module_name} ($module_passed/$module_total passed, $(printf "%.2f" $module_time)s)${NC}"
        # Save failed tests for later reporting
        grep -A 1 "FAIL:\|ERROR:" "$results_file" >> "$failed_tests_file"
    fi
    
    # Generate coverage report if available
    if [ "$has_coverage" = true ]; then
        coverage xml -o "$coverage_file" > /dev/null 2>&1
    fi
}

# Find all test directories
echo -e "${BLUE}Discovering test modules...${NC}"
test_dirs=$(find ./refactor -type d -path "*/tests*" | sort)

if [ -z "$test_dirs" ]; then
    echo -e "${YELLOW}No test directories found.${NC}"
    echo -e "${YELLOW}Looking for individual test files...${NC}"
    test_files=$(find ./refactor -name "test_*.py" | sort)
    
    if [ -z "$test_files" ]; then
        echo -e "${RED}No test files found. Exiting.${NC}"
        exit 1
    else
        # Run each test file individually
        for test_file in $test_files; do
            test_dir=$(dirname "$test_file")
            run_module_tests "$test_dir"
        done
    fi
else
    # Run tests for each directory
    for dir in $test_dirs; do
        run_module_tests "$dir"
    done
fi

echo ""
echo -e "${BOLD}${BLUE}=========================================${NC}"
echo -e "${BOLD}${BLUE}            Test Summary                 ${NC}"
echo -e "${BOLD}${BLUE}=========================================${NC}"
echo ""

# Calculate percentages safely
pass_percent=0.0
fail_percent=0.0
error_percent=0.0
skip_percent=0.0

if [ "$total_tests" -gt 0 ]; then
    pass_percent=$(echo "scale=1; $passed_tests * 100 / $total_tests" | bc)
    fail_percent=$(echo "scale=1; $failed_tests * 100 / $total_tests" | bc)
    error_percent=$(echo "scale=1; $error_tests * 100 / $total_tests" | bc)
    skip_percent=$(echo "scale=1; $skipped_tests * 100 / $total_tests" | bc)
fi

# Print test summary
echo "Test Results:"
echo "  Total tests:  $total_tests"
echo "  Passed:       $passed_tests ($pass_percent%)"
echo "  Failed:       $failed_tests ($fail_percent%)"
echo "  Errors:       $error_tests ($error_percent%)"
echo "  Skipped:      $skipped_tests ($skip_percent%)"
echo ""

echo "Timing:"
echo "  Total execution time: ${total_time}s"

# Print average time if tests were executed
if [ "$total_tests" -gt 0 ]; then
    avg_time=$(echo "scale=3; $total_time / $total_tests" | bc)
    echo "  Average time per test: ${avg_time}s"
else
    echo "  No tests found to calculate average time."
fi

echo ""

# Show appropriate message based on test results
if [ "$total_tests" -eq 0 ]; then
    echo "No tests were found or executed!"
elif [ "$failed_tests" -eq 0 ] && [ "$error_tests" -eq 0 ]; then
    echo "All tests passed successfully!"
else
    echo "Some tests failed or had errors. Check the output above for details."
fi

# Display coverage information if available
if [ "$has_coverage" = true ]; then
    echo ""
    echo -e "${BOLD}Coverage:${NC}"
    
    if [ -f "$coverage_file" ]; then
        coverage_percent=$(grep "line-rate=" "$coverage_file" | head -1 | grep -oP 'line-rate="\K[^"]+')
        if [ -n "$coverage_percent" ]; then
            # Convert decimal to percentage
            coverage_percent=$(echo "scale=1; ${coverage_percent}*100" | bc)
            echo -e "  Line coverage: ${coverage_percent}%"
            
            # Print coverage by module
            echo -e "  ${BOLD}Coverage by module:${NC}"
            grep "class filename" "$coverage_file" | grep -oP 'filename="\K[^"]+' | while read -r file; do
                module_coverage=$(grep -A1 "filename=\"$file\"" "$coverage_file" | grep -oP 'line-rate="\K[^"]+' | head -1)
                if [ -n "$module_coverage" ]; then
                    module_coverage=$(echo "scale=1; ${module_coverage}*100" | bc)
                    echo -e "    $(basename "$file"): ${module_coverage}%"
                fi
            done
        else
            echo -e "  ${YELLOW}Unable to parse coverage data${NC}"
        fi
    else
        echo -e "  ${YELLOW}No coverage data available${NC}"
    fi
fi

# Display failed tests in detail
if [ -f "$failed_tests_file" ] && [ -s "$failed_tests_file" ]; then
    echo ""
    echo -e "${BOLD}${RED}Failed Tests:${NC}"
    cat "$failed_tests_file" | sed 's/^/  /'
fi

# Clean up temporary directory
rm -rf "$tmp_dir"

# Exit with appropriate status code
if [ "$failed_tests" -gt 0 ] || [ "$error_tests" -gt 0 ]; then
    echo ""
    echo -e "${RED}Tests completed with failures or errors.${NC}"
    exit 1
else
    echo ""
    if [ "$total_tests" -eq 0 ]; then
        echo -e "${YELLOW}No tests were found or executed!${NC}"
        exit 0
    else
        echo -e "${GREEN}All tests passed successfully!${NC}"
        exit 0
    fi
fi 